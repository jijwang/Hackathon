{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WousIcEWleA-"
      },
      "outputs": [],
      "source": [
        "! pip install -qU llama-index-llms-google-genai llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_gXiszgmsmb"
      },
      "outputs": [],
      "source": [
        "# note: this only works when run in colab!\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "llm = GoogleGenAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    api_key=GOOGLE_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yebJxsIm8TE"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import CustomQueryEngine\n",
        "\n",
        "import json\n",
        "import requests\n",
        "\n",
        "GMICLOUD_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjY2ZjY4ZGNiLTc2MjYtNDU1YS04MTJlLWNjZWQ0NGM1MmFmMSIsInR5cGUiOiJpZV9tb2RlbCJ9.wSR0pMUfjAfTijf8jJSaiec1FutdKCcCJq6RlJo62uM\"\n",
        "\n",
        "class QueryEngineDeepSeekR1(CustomQueryEngine):\n",
        "\n",
        "    def custom_query(self, msg):\n",
        "        # You can add logging, error handling, or preprocessing here\n",
        "        url = \"https://api.gmi-serving.com/v1/chat/completions\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": \"Bearer \" + GMICLOUD_API_KEY\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-ai/DeepSeek-R1-0528\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": msg}\n",
        "            ],\n",
        "            \"temperature\": 0,\n",
        "            \"max_tokens\": 500\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        return json.dumps(response.json())\n",
        "\n",
        "class QueryEngineDeepSeekV2(CustomQueryEngine):\n",
        "\n",
        "    def custom_query(self, msg):\n",
        "        # You can add logging, error handling, or preprocessing here\n",
        "        url = \"https://api.gmi-serving.com/v1/chat/completions\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": \"Bearer \" + GMICLOUD_API_KEY\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-ai/DeepSeek-Prover-V2-671B\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": msg}\n",
        "            ],\n",
        "            \"temperature\": 0,\n",
        "            \"max_tokens\": 500\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        return json.dumps(response.json())\n",
        "\n",
        "class QueryEngineQWen(CustomQueryEngine):\n",
        "\n",
        "    def custom_query(self, msg):\n",
        "        # You can add logging, error handling, or preprocessing here\n",
        "        url = \"https://api.gmi-serving.com/v1/chat/completions\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": \"Bearer \" + GMICLOUD_API_KEY\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"Qwen/Qwen3-32B-FP8\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": msg}\n",
        "            ],\n",
        "            \"temperature\": 0,\n",
        "            \"max_tokens\": 500\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        return json.dumps(response.json())\n",
        "\n",
        "engine_deepseek_r1 = QueryEngineDeepSeekR1()\n",
        "engine_deepseek_v2 = QueryEngineDeepSeekV2()\n",
        "engine_qwen = QueryEngineQWen()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCDLWqvHOa3F"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "tool_deepseek_r1 = QueryEngineTool(\n",
        "    query_engine = engine_deepseek_r1,\n",
        "    metadata = ToolMetadata(\n",
        "    name=\"query_deepseek_r1\",\n",
        "    description=\"Tool to query deepseek r1\"\n",
        "    ),\n",
        ")\n",
        "tool_deepseek_v2 = QueryEngineTool(\n",
        "    query_engine = engine_deepseek_v2,\n",
        "    metadata = ToolMetadata(\n",
        "        name=\"query_deepseek_v2\",\n",
        "        description=\"Tool to query deepseek v2\"\n",
        "    ),\n",
        ")\n",
        "tool_qwen = QueryEngineTool(\n",
        "    query_engine = engine_qwen,\n",
        "    metadata = ToolMetadata(\n",
        "        name=\"query_qwen\",\n",
        "        description=\"Tool to query qwen\"\n",
        "    ),\n",
        ")\n",
        "tools = [tool_deepseek_r1, tool_deepseek_v2, tool_qwen]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytH2PneenTeP",
        "outputId": "ef5635c1-d0b9-4625-81b7-9373ae45a74c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 1c7930d6-6fe5-4d40-a606-d192087c85e7. Step input: hi, what is a deadlock?\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: query_deepseek_r1\n",
            "Action Input: {'input': 'what is a deadlock in computer science?'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {\"id\": \"972d7134eea5430797e747e89080fbeb\", \"object\": \"chat.completion\", \"created\": 1750015677, \"model\": \"deepseek-ai/DeepSeek-R1-0528\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"A **deadlock** in computer science is a situation where **two or more processes (or threads) are permanently blocked**, each waiting for the other to release a resource (like memory, files, or hardware) before it can proceed. None can advance, causing the system to freeze.\\n\\n### Key Conditions for Deadlock (Coffman Conditions)\\nAll four must hold simultaneously for a deadlock to occur:\\n1.  **Mutual Exclusion**: Resources cannot be shared (only one process can use a resource at a time).\\n2.  **Hold and Wait**: Processes hold resources while waiting for others.\\n3.  **No Preemption**: Resources cannot be forcibly taken from a process (only voluntarily released).\\n4.  **Circular Wait**: A cycle exists where each process waits for a resource held by the next process in the cycle (e.g., Process A waits for Resource 1 held by B; Process B waits for Resource 2 held by\", \"reasoning_content\": \"Okay, the user is asking about deadlocks in computer science. This seems like a fundamental concept in operating systems or concurrent programming. \\n\\nHmm, judging by the straightforward question, the user might be a student studying computer science basics, or perhaps a developer who encountered the term in practice. The simplicity of the question suggests they want a clear conceptual explanation rather than advanced details. \\n\\nI should start with the classic definition but make it concrete. The dining philosophers example always works well - it's visual and relatable. Need to emphasize that deadlock isn't just about waiting, but the circular dependency aspect. \\n\\nAh, the four conditions are crucial here. Must present them logically: mutual exclusion first because it's foundational, then hold-and-wait which explains why resources get stuck, then no preemption as the policy constraint, and finally circular wait as the structural manifestation. \\n\\nWait, should I mention livelock? No, that might confuse them when they're asking specifically about deadlock. Stay focused. \\n\\nFor prevention strategies, I'll organize them by which condition they break. The banker's algorithm might be too much detail though - just naming it as a detection method should suffice. \\n\\nThe real-world analogy with traffic gridlock feels helpful to cement understanding. People grasp traffic jams more intuitively than process scheduling. \\n\\n...Better avoid getting too technical about resource allocation graphs. The key is they understand the concept and can recognize the four conditions. If they need implementation-level solutions, they'll ask follow-ups.\\n\", \"tool_calls\": null}, \"logprobs\": null, \"finish_reason\": \"length\", \"matched_stop\": null}], \"usage\": {\"prompt_tokens\": 12, \"total_tokens\": 512, \"completion_tokens\": 500, \"prompt_tokens_details\": null}}\n",
            "\u001b[0m> Running step f59211d2-2441-4803-8c30-99acd2cd3bba. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: A deadlock in computer science is a situation where two or more processes (or threads) are permanently blocked, each waiting for the other to release a resource (like memory, files, or hardware) before it can proceed. None can advance, causing the system to freeze.\n",
            "\n",
            "Key Conditions for Deadlock (Coffman Conditions)\n",
            "All four must hold simultaneously for a deadlock to occur:\n",
            "1. Mutual Exclusion: Resources cannot be shared (only one process can use a resource at a time).\n",
            "2. Hold and Wait: Processes hold resources while waiting for others.\n",
            "3. No Preemption: Resources cannot be forcibly taken from a process (only voluntarily released).\n",
            "4. Circular Wait: A cycle exists where each process waits for a resource held by the next process in the cycle (e.g., Process A waits for Resource 1 held by B; Process B waits for Resource 2 held by\n",
            "\u001b[0mAgent: A deadlock in computer science is a situation where two or more processes (or threads) are permanently blocked, each waiting for the other to release a resource (like memory, files, or hardware) before it can proceed. None can advance, causing the system to freeze.\n",
            "\n",
            "Key Conditions for Deadlock (Coffman Conditions)\n",
            "All four must hold simultaneously for a deadlock to occur:\n",
            "1. Mutual Exclusion: Resources cannot be shared (only one process can use a resource at a time).\n",
            "2. Hold and Wait: Processes hold resources while waiting for others.\n",
            "3. No Preemption: Resources cannot be forcibly taken from a process (only voluntarily released).\n",
            "4. Circular Wait: A cycle exists where each process waits for a resource held by the next process in the cycle (e.g., Process A waits for Resource 1 held by B; Process B waits for Resource 2 held by\n"
          ]
        }
      ],
      "source": [
        "agent = ReActAgent.from_tools(\n",
        "    tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_turns=10,\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    response = agent.chat(user_input)\n",
        "    print(\"Agent:\", response.response)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}